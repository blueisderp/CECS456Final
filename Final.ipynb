{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "d_NqCbXpTARK"
      },
      "outputs": [],
      "source": [
        "# Le Duong\n",
        "# CECS 456 Final Project - Natural Images with 8 classes\n",
        "# Prof. Zheng\n",
        "# 5/15/2024\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading Dataset\n",
        "\n",
        "# download and extract dataset\n",
        "!pip install kaggle\n",
        "!kaggle datasets download prasunroy/natural-images\n",
        "with zipfile.ZipFile('natural-images.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('natural-images')\n",
        "\n",
        "# load dataset\n",
        "data_dir = 'natural-images/natural_images'  # Directory containing the dataset\n",
        "classes = os.listdir(data_dir) # different classifications in dataset (8 total)\n",
        "\n",
        "# initialize empty lists to store images and labels\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "# iterate through each class directory\n",
        "for i, class_name in enumerate(classes):\n",
        "    class_dir = os.path.join(data_dir, class_name)\n",
        "    # iterate through each image in the class directory\n",
        "    for image_name in os.listdir(class_dir):\n",
        "        # load image\n",
        "        image_path = os.path.join(class_dir, image_name)\n",
        "        image = Image.open(image_path)\n",
        "        # resize and normalize the image so its consistent\n",
        "        image = image.resize((28, 28))\n",
        "        image = np.array(image) / 255.0\n",
        "        # append the image and its corresponding label to the lists\n",
        "        images.append(image)\n",
        "        labels.append(i)\n",
        "\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# split  dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "#  split the training set further into training and validation sets\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5glQ3IBvTDqB",
        "outputId": "7911a2c3-bbd2-47ce-e8cc-1638574c3b15"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.12)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.4)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.7)\n",
            "Dataset URL: https://www.kaggle.com/datasets/prasunroy/natural-images\n",
            "License(s): CC-BY-NC-SA-4.0\n",
            "natural-images.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert target labels to one-hot encoded vectors (so that target label shape matches model output shape)\n",
        "y_train= tf.keras.utils.to_categorical(y_train, num_classes=len(classes))\n",
        "y_valid= tf.keras.utils.to_categorical(y_valid, num_classes=len(classes))\n",
        "y_test= tf.keras.utils.to_categorical(y_test, num_classes=len(classes))"
      ],
      "metadata": {
        "id": "78_vT0AviQfo"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build CNN Model\n",
        "\n",
        "# initialize the CNN model\n",
        "cnn = tf.keras.models.Sequential()\n",
        "\n",
        "# convolutional layers\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\", padding=\"same\", input_shape=[28, 28, 3]))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\", padding=\"same\"))\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\", padding=\"same\"))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\", padding=\"same\"))\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\", padding=\"same\"))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "\n",
        "# flatten layer\n",
        "cnn.add(tf.keras.layers.Flatten())\n",
        "\n",
        "# dense layers with L2 regularization\n",
        "cnn.add(tf.keras.layers.Dense(units=128, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
        "cnn.add(tf.keras.layers.Dropout(0.5))\n",
        "cnn.add(tf.keras.layers.Dense(units=64, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
        "cnn.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "# output layer\n",
        "cnn.add(tf.keras.layers.Dense(units=len(classes), activation=\"softmax\"))\n",
        "\n",
        "# display model summary\n",
        "cnn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuZtxTiyZGnL",
        "outputId": "8832b696-bc13-4fd2-d5f9-6514a4dee4fe"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_70 (Conv2D)          (None, 28, 28, 64)        1792      \n",
            "                                                                 \n",
            " max_pooling2d_42 (MaxPooli  (None, 14, 14, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_71 (Conv2D)          (None, 14, 14, 128)       73856     \n",
            "                                                                 \n",
            " conv2d_72 (Conv2D)          (None, 14, 14, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_43 (MaxPooli  (None, 7, 7, 128)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_73 (Conv2D)          (None, 7, 7, 256)         295168    \n",
            "                                                                 \n",
            " conv2d_74 (Conv2D)          (None, 7, 7, 256)         590080    \n",
            "                                                                 \n",
            " max_pooling2d_44 (MaxPooli  (None, 3, 3, 256)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_14 (Flatten)        (None, 2304)              0         \n",
            "                                                                 \n",
            " dense_42 (Dense)            (None, 128)               295040    \n",
            "                                                                 \n",
            " dropout_28 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_43 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_29 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_44 (Dense)            (None, 8)                 520       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1412296 (5.39 MB)\n",
            "Trainable params: 1412296 (5.39 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "cnn.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "dLd6hlOVZpko"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = cnn.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    batch_size=100,\n",
        "    epochs=5,\n",
        "    validation_data=(X_valid, y_valid)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0Cw7XNs6aEiy",
        "outputId": "12210d2d-0334-4890-c7fa-ce23b78db9bd"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "45/45 [==============================] - 60s 1s/step - loss: 0.6621 - accuracy: 0.8492 - val_loss: 1.1406 - val_accuracy: 0.7364\n",
            "Epoch 2/5\n",
            "45/45 [==============================] - 62s 1s/step - loss: 0.5975 - accuracy: 0.8582 - val_loss: 1.1984 - val_accuracy: 0.6341\n",
            "Epoch 3/5\n",
            "45/45 [==============================] - 62s 1s/step - loss: 0.5706 - accuracy: 0.8648 - val_loss: 1.0172 - val_accuracy: 0.6821\n",
            "Epoch 4/5\n",
            "45/45 [==============================] - 64s 1s/step - loss: 0.4893 - accuracy: 0.8815 - val_loss: 0.8828 - val_accuracy: 0.7210\n",
            "Epoch 5/5\n",
            "45/45 [==============================] - 66s 1s/step - loss: 0.4382 - accuracy: 0.8981 - val_loss: 0.6660 - val_accuracy: 0.8043\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation of model against test set\n",
        "score = cnn.evaluate(X_test, y_test)\n",
        "print('Total loss on Testing Set:', score[0])\n",
        "print('Accuracy of Testing Set:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3y_sJGDgOLQ",
        "outputId": "76abd17f-f9fe-4135-8525-6d50095e899c"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44/44 [==============================] - 4s 100ms/step - loss: 0.6222 - accuracy: 0.8442\n",
            "Total loss on Testing Set: 0.6222281455993652\n",
            "Accuracy of Testing Set: 0.8442028760910034\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting the first three images from the test set\n",
        "# print the predicted results of the first three images from the test set\n",
        "# print the real label of the first three images from the test set\n",
        "\n",
        "# classifications from dataset\n",
        "class_names = [\"airplanes\", \"car\", \"cat\", \"dog\", \"flower\", \"fruit\", \"motorbike\", \"person\"]\n",
        "\n",
        "# extracting true labels for the first three images from the test set\n",
        "y_new = np.argmax(y_test[:3], axis=1)\n",
        "\n",
        "# predicting the first three images from the test set\n",
        "predictions = cnn.predict(X_test[:3])\n",
        "\n",
        "# decode the predicted labels\n",
        "predicted_labels = [class_names[np.argmax(pred)] for pred in predictions]\n",
        "\n",
        "# print the predicted results\n",
        "print(\"Predicted Results:\")\n",
        "for i, label in enumerate(predicted_labels):\n",
        "    print(f\"Image {i+1}: {label}\")\n",
        "\n",
        "# print the real labels of the first three images from the test set\n",
        "print(\"\\nReal Labels:\")\n",
        "for i in range(3):\n",
        "    print(f\"Image {i+1}: {class_names[y_new[i]]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MD0Rv7MOzxZj",
        "outputId": "eeeff97a-96c2-40ad-9f0a-90f57f949072"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 55ms/step\n",
            "Predicted Results:\n",
            "Image 1: airplanes\n",
            "Image 2: cat\n",
            "Image 3: flower\n",
            "\n",
            "Real Labels:\n",
            "Image 1: airplanes\n",
            "Image 2: cat\n",
            "Image 3: flower\n"
          ]
        }
      ]
    }
  ]
}